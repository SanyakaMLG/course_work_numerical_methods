{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d117d7-d3db-4746-abdc-f7528432bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision import transforms, models\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b40a4-4c43-4395-bc4b-6c862b852fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = '42'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e5a9e-d834-4e36-8bb0-a8660b875aa6",
   "metadata": {},
   "source": [
    "# Data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6753e433-d836-4839-b313-51682a4366b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data_dir):\n",
    "    data = []\n",
    "    for split in ['train', 'test']:\n",
    "        for label in ['benign', 'malignant']:\n",
    "            folder = os.path.join(data_dir, split, label)\n",
    "            for filename in os.listdir(folder):\n",
    "                if filename.endswith(('.png', '.jpg', '.jpeg')):  # Убедимся, что это изображение\n",
    "                    filepath = os.path.join(folder, filename)\n",
    "                    data.append({\n",
    "                        'path': filepath,\n",
    "                        'label': 0 if label == 'benign' else 1,\n",
    "                        'split': split\n",
    "                    })\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c23b3e5-b048-4d21-9385-9645e139067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "dataframe = create_dataframe(data_dir)\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acba639-c238-454d-9f75-7e2cf48da191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        image_path = row['path']\n",
    "        label = row['label']\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ded20-2a71-42b6-b43d-d610ff4aeb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "def get_dataloader(dataframe, transform, batch_size=32, shuffle=True):\n",
    "    dataset = ImageDataset(dataframe, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_df = dataframe[dataframe['split'] == 'train'].copy().reset_index(drop=True)\n",
    "test_df = dataframe[dataframe['split'] == 'test'].copy().reset_index(drop=True)\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = get_dataloader(train_df, transform=transform, batch_size=192, shuffle=True)\n",
    "val_loader   = get_dataloader(val_df,   transform=transform, batch_size=192, shuffle=False)\n",
    "test_loader  = get_dataloader(test_df,  transform=transform, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869fe4d-f02c-40c5-8b5b-48e2b9dca2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in dataframe.iterrows():\n",
    "    image_path = row['path']\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    torch.save(image, f\"processed/{idx}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638fffa-7dac-4b34-b941-971b40e3dd4f",
   "metadata": {},
   "source": [
    "# FlexibleResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac3ed2-b842-4e27-9279-338f60bbd502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, activation=nn.ReLU):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.activation = activation()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.activation(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976909c0-6656-491c-9712-0dd8456992da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_planes, planes, stride=1, activation=nn.ReLU):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.activation = activation()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes * self.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.bn1(self.conv1(x)))\n",
    "        out = self.activation(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e89e4-14ee-42c4-9eb2-88448216b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleResNet(nn.Module):\n",
    "    def __init__(self, block_type, num_blocks_list, \n",
    "                 num_classes=2, \n",
    "                 activation_name=\"relu\",\n",
    "                 base_channels=64):\n",
    "        \"\"\"\n",
    "        block_type: класс блока (BasicBlock или Bottleneck)\n",
    "        num_blocks_list: список [n1, n2, n3, n4] (сколько блоков в каждом из 4-х stage)\n",
    "        activation_name: \"relu\" / \"tanh\" / \"sigmoid\"\n",
    "        base_channels: кол-во каналов в первой свёртке\n",
    "        \"\"\"\n",
    "        super(FlexibleResNet, self).__init__()\n",
    "\n",
    "        act_map = {\n",
    "            \"relu\": nn.ReLU,\n",
    "            \"tanh\": nn.Tanh,\n",
    "            \"sigmoid\": nn.Sigmoid\n",
    "        }\n",
    "        self.activation = act_map.get(activation_name, nn.ReLU)\n",
    "\n",
    "        self.in_planes = base_channels\n",
    "        self.block = block_type\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=7, stride=2,\n",
    "                               padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.act1 = self.activation()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(self.block, base_channels,      num_blocks_list[0], stride=1)\n",
    "        self.layer2 = self._make_layer(self.block, base_channels*2,    num_blocks_list[1], stride=2)\n",
    "        self.layer3 = self._make_layer(self.block, base_channels*4,    num_blocks_list[2], stride=2)\n",
    "        self.layer4 = self._make_layer(self.block, base_channels*8,    num_blocks_list[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        final_planes = (base_channels*8) * (block_type.expansion if hasattr(block_type, 'expansion') else 1)\n",
    "        self.fc = nn.Linear(final_planes, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        layers = []\n",
    "\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_planes, planes, s, activation=self.activation))\n",
    "            if hasattr(block, 'expansion'):\n",
    "                self.in_planes = planes * block.expansion\n",
    "            else:\n",
    "                self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.act1(self.bn1(self.conv1(x))))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97316dc4-3b6b-4a16-836e-2d21ef9e10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet34(num_classes=1000, activation_name=\"relu\"):\n",
    "    return FlexibleResNet(\n",
    "        block_type=BasicBlock,\n",
    "        num_blocks_list=[3, 4, 6, 3],\n",
    "        num_classes=num_classes,\n",
    "        activation_name=activation_name,\n",
    "        base_channels=64\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ea78a-7137-4bf9-b137-87d9084116b1",
   "metadata": {},
   "source": [
    "# Train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2b517-9add-4544-9832-692d65c56fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Статистика\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0799a45-3c1d-440d-bd69-4d0bfd9a76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, criterion, test_loader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c938e-912b-4fab-a173-9a2f50596c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calc_roc_auc_score(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "            all_probs.extend(probs)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c14dda-e9ba-4ed2-9c0c-1ca714c26dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "def calc_pr_auc_score(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "            \n",
    "            all_probs.extend(probs)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
    "\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return pr_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9764832c-9232-4845-9f5a-6dad57c646d4",
   "metadata": {},
   "source": [
    "# Train resnet34 with different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e1fd5-2f17-4352-9869-87e2761d0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(num_classes=2):\n",
    "    model = models.resnet34(pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f7619-89e5-4d1a-8089-80191562f662",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet34(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "best_test_acc = 0.0\n",
    "best_model_path = \"best_model_sgd.pth\"\n",
    "\n",
    "for epoch in range(1, 26):\n",
    "    train_loss, train_acc = train_model(model, criterion, optimizer, train_loader, device)\n",
    "    test_loss, test_acc = evaluate_model(model, criterion, val_loader, device)\n",
    "    \n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Лучшее состояние модели сохранено с точностью валидации {best_test_acc:.2f}%\")\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\\n\"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "test_loss, test_acc = evaluate_model(model, criterion, test_loader, device)\n",
    "print(f'\\n\\nFinal Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d02ba-0016-46ee-8734-a3712e93c8ed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet34(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, nesterov=True, momentum=0.9)\n",
    "\n",
    "best_test_acc = 0.0\n",
    "best_model_path = \"best_model_nag.pth\"\n",
    "\n",
    "for epoch in range(1, 26):\n",
    "    train_loss, train_acc = train_model(model, criterion, optimizer, train_loader, device)\n",
    "    test_loss, test_acc = evaluate_model(model, criterion, val_loader, device)\n",
    "    \n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Лучшее состояние модели сохранено с точностью валидации {best_test_acc:.2f}%\")\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\\n\"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "test_loss, test_acc = evaluate_model(model, criterion, test_loader, device)\n",
    "print(f'\\n\\nFinal Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15583eb6-155b-4ea0-b399-cd201de1de47",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet34(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.005)\n",
    "\n",
    "best_test_acc = 0.0\n",
    "best_model_path = \"best_model_adagrad.pth\"\n",
    "\n",
    "for epoch in range(1, 50):\n",
    "    train_loss, train_acc = train_model(model, criterion, optimizer, train_loader, device)\n",
    "    test_loss, test_acc = evaluate_model(model, criterion, val_loader, device)\n",
    "    \n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Лучшее состояние модели сохранено с точностью валидации {best_test_acc:.2f}%\")\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\\n\"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "test_loss, test_acc = evaluate_model(model, criterion, test_loader, device)\n",
    "print(f'\\n\\nFinal Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ecd3d-b4f4-4e8b-9b1c-9d9c820d5101",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet34(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.003)\n",
    "\n",
    "best_test_acc = 0.0\n",
    "best_model_path = \"best_model_rmsprop.pth\"\n",
    "\n",
    "for epoch in range(1, 76):\n",
    "    train_loss, train_acc = train_model(model, criterion, optimizer, train_loader, device)\n",
    "    test_loss, test_acc = evaluate_model(model, criterion, val_loader, device)\n",
    "    \n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Лучшее состояние модели сохранено с точностью валидации {best_test_acc:.2f}%\")\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\\n\"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "test_loss, test_acc = evaluate_model(model, criterion, test_loader, device)\n",
    "print(f'\\n\\nFinal Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612afca-0eac-4ae4-9bfd-19bef79687cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet34(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_test_acc = 0.0\n",
    "best_model_path = \"best_model_adam.pth\"\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    train_loss, train_acc = train_model(model, criterion, optimizer, train_loader, device)\n",
    "    test_loss, test_acc = evaluate_model(model, criterion, val_loader, device)\n",
    "    \n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Лучшее состояние модели сохранено с точностью валидации {best_test_acc:.2f}%\")\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\\n\"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "test_loss, test_acc = evaluate_model(model, criterion, test_loader, device)\n",
    "print(f'\\n\\nFinal Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a9a063-ccf6-4c68-8110-d3b50da34305",
   "metadata": {},
   "source": [
    "# Metrics on resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c7aa7-5829-4f0d-beee-0779a579df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_adam.pth'))\n",
    "model.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b802c55-db31-49eb-b76b-38dc0db65439",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_roc_auc_score(model, test_loader, device))\n",
    "print(calc_pr_auc_score(model, test_loader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa3241-12b2-4fb3-b42d-38e6e7e48c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_sgd.pth'))\n",
    "model.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b97a2-c016-4749-922e-b6f33b508750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_roc_auc_score(model, test_loader, device))\n",
    "print(calc_pr_auc_score(model, test_loader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9315f-85c5-41a9-b1a0-8a58bf03d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_nag.pth'))\n",
    "model.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f419e1-906c-470f-9cc6-1fc15bb75403",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_roc_auc_score(model, test_loader, device))\n",
    "print(calc_pr_auc_score(model, test_loader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b438c9b-dcd8-44c5-8490-a0a9cc754567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_adagrad.pth'))\n",
    "model.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b590a-936d-41dd-a7f2-597a2d80bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_roc_auc_score(model, test_loader, device))\n",
    "print(calc_pr_auc_score(model, test_loader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e45d5e-79af-4f27-8084-c64c60d5b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_rmsprop.pth'))\n",
    "model.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a4665-287f-4b31-b500-77f782c96015",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_roc_auc_score(model, test_loader, device))\n",
    "print(calc_pr_auc_score(model, test_loader, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9ac35-05d5-4344-90d6-5aa42d5d99ba",
   "metadata": {},
   "source": [
    "# Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6111c9b1-f75f-444d-b1e7-1405ee03a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_dict, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        index = self.dataframe.index[idx]\n",
    "        image = images_dict[index]\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "images_dict = {}\n",
    "for idx, row in dataframe.iterrows():\n",
    "    images_dict[idx] = torch.load(f'processed/{idx}.pt')\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "def get_dataloader(dataframe, images_dict, transform, batch_size=32, shuffle=True):\n",
    "    dataset = ImageDataset(dataframe, images_dict, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_df = dataframe[dataframe['split'] == 'train'].copy()\n",
    "test_df = dataframe[dataframe['split'] == 'test'].copy()\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = get_dataloader(train_df, images_dict, transform=transform, batch_size=64, shuffle=True)\n",
    "val_loader   = get_dataloader(val_df,   images_dict, transform=transform, batch_size=64, shuffle=False)\n",
    "test_loader  = get_dataloader(test_df,  images_dict, transform=transform, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f935b6-b45a-404b-ba8d-fbe83fa6d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FlexibleResNet(\n",
    "    block_type=Bottleneck,\n",
    "    num_blocks_list=[2, 3, 2, 4],\n",
    "    num_classes=2,\n",
    "    activation_name='relu',\n",
    "    base_channels=64\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, nesterov=True, momentum=0.9)\n",
    "\n",
    "best_test_acc = 0.0\n",
    "best_model_path = \"resnet_ga_nag.pth\"\n",
    "\n",
    "for epoch in range(1, 26):\n",
    "    train_loss, train_acc = train_model(model, criterion, optimizer, train_loader, device)\n",
    "    test_loss, test_acc = evaluate_model(model, criterion, val_loader, device)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Лучшее состояние модели сохранено с точностью валидации {best_test_acc:.2f}%\")\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\\n\"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "    test_loss, test_acc = evaluate_model(model, criterion, test_loader, device)\n",
    "    print(f'\\n\\nFinal Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524ff63a-e62f-427a-a3ce-1490591c54de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('resnet_ga_nag.pth'))\n",
    "model.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096f790-0563-4377-adaa-58573d568828",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_roc_auc_score(model, test_loader, device))\n",
    "print(calc_pr_auc_score(model, test_loader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d687b2-d834-4e4f-ab79-5f65686867c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate_model(model, criterion, test_loader, device)\n",
    "print(f'\\n\\nFinal Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5de3f-166d-4d56-927c-3603e06355d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
